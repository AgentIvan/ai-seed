{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor with StandardScaler\n",
    "\n",
    "### Required Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as se \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Filepath of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-704189645918>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#filepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\Machine Learning and Deep Learning\\Data\\BlobCity_DATA.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#filepath\n",
    "import \n",
    "file_path= os.path.join(\"D:\\Machine Learning and Deep Learning\\Data\\BlobCity_DATA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of features which are  required for model training ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_values\n",
    "features=[\"AT\", \"V\", \"AP\", \"RH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_value\n",
    "target='PE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fetching\n",
    "\n",
    "Pandas is an open-source, BSD-licensed library providing high-performance, easy-to-use data manipulation and data analysis tools.\n",
    "\n",
    "We will use panda's library to read the CSV file using its storage path.And we use the head function to display the initial row or entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selections\n",
    "\n",
    "It is the process of reducing the number of input variables when developing a predictive model. Used to reduce the number of input variables to both reduce the computational cost of modelling and, in some cases, to improve the performance of the model.\n",
    "\n",
    "We will assign all the required input features to X and target/outcome to Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "Y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Since the majority of the machine learning models in the Sklearn library doesn't handle string category data and Null value, we have to explicitly remove or replace null values. The below snippet have functions, which removes the null value if any exists. And convert the string classes data in the datasets by encoding them to integer classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NullClearner(df):\n",
    "    if(isinstance(df, pd.Series) and (df.dtype in [\"float64\",\"int64\"])):\n",
    "        df.fillna(df.mean(),inplace=True)\n",
    "        return df\n",
    "    elif(isinstance(df, pd.Series)):\n",
    "        df.fillna(df.mode()[0],inplace=True)\n",
    "        return df\n",
    "    else:return df\n",
    "def EncodeX(df):\n",
    "    return pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling preprocessing functions on the feature and target set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X.columns.to_list()\n",
    "for i in x:\n",
    "    X[i]=NullClearner(X[i])\n",
    "X=EncodeX(X)\n",
    "Y=NullClearner(Y)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Map\n",
    "\n",
    "In order to check the correlation between the features, we will plot a correlation matrix. It is effective in summarizing a large amount of data where the goal is to see patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(18, 18))\n",
    "matrix = np.triu(X.corr())\n",
    "se.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax, mask=matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "The train-test split is a procedure for evaluating the performance of an algorithm. The procedure involves taking a dataset and dividing it into two subsets. The first subset is utilized to fit/train the model. The second subset is used for prediction. The main motive is to estimate the performance of the model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Rescaling\n",
    "\n",
    "Performing StandardScaler data rescaling operation on dataset. The StandardScaler standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "We will fit an object of StandardScaler to **train data** then transform the same data via <Code>fit_transform(X_train)</Code> method, following which we will transform **test data** via <Code>transform(X_test)</Code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the <code>max_samples</code> parameter if <code>bootstrap=True</code> (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "#### Model Tuning Parameters\n",
    "\n",
    "    1. n_estimators : int, default=100\n",
    "> The number of trees in the forest.\n",
    "\n",
    "    2. criterion : {“mae”, “mse”}, default=”mse”\n",
    "> The function to measure the quality of a split. Supported criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion, and “mae” for the mean absolute error.\n",
    "\n",
    "    3. max_depth : int, default=None\n",
    "> The maximum depth of the tree.\n",
    "\n",
    "    4. max_features : {“auto”, “sqrt”, “log2”}, int or float, default=”auto”\n",
    "> The number of features to consider when looking for the best split:\n",
    "\n",
    "\n",
    "    5. bootstrap : bool, default=True\n",
    "> Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "    6. oob_score : bool, default=False\n",
    "> Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
    "\n",
    "    7. n_jobs : int, default=None\n",
    "> The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees. <code>None</code> means 1 unless in a joblib.parallel_backend context. <code>-1</code> means using all processors. See Glossary for more details.\n",
    "\n",
    "    8. random_state : int, RandomState instance or None, default=None\n",
    "> Controls both the randomness of the bootstrapping of the samples used when building trees (if <code>bootstrap=True</code>) and the sampling of the features to consider when looking for the best split at each node (if <code>max_features < n_features</code>).\n",
    "\n",
    "    9. verbose : int, default=0\n",
    "> Controls the verbosity when fitting and predicting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs = -1,random_state = 123)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy\n",
    "\n",
    "We will use the trained model to make a prediction on the test set.Then use the predicted value for measuring the accuracy of our model.\n",
    "\n",
    "> **score**: The **score** function returns the coefficient of determination <code>R<sup>2</sup></code> of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score {:.2f} %\\n\".format(model.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **r2_score**: The **r2_score** function computes the percentage variablility explained by our model, either the fraction or the count of correct predictions.  \n",
    "\n",
    "> **mae**: The **mean abosolute error** function calculates the amount of total error(absolute average distance between the real data and the predicted data) by our model.  \n",
    "\n",
    "> **mse**: The **mean squared error** function squares the error(penalizes the model for large errors) by our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(\"R2 Score: {:.2f} %\".format(r2_score(y_test,y_pred)*100))\n",
    "print(\"Mean Absolute Error {:.2f}\".format(mean_absolute_error(y_test,y_pred)))\n",
    "print(\"Mean Squared Error {:.2f}\".format(mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importances\n",
    "\n",
    "The Feature importance refers to techniques that assign a score to features based on how useful they are for making the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "n_features = len(X.columns)\n",
    "plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(n_features), X.columns)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Plot\n",
    "\n",
    "First, we make use of a plot to plot the actual observations, with x_train on the x-axis and y_train on the y-axis.\n",
    "For the regression line, we will use x_train on the x-axis and then the predictions of the x_train observations on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.plot(range(20),y_test[0:20], color = \"green\")\n",
    "plt.plot(range(20),model.predict(X_test[0:20]), color = \"red\")\n",
    "plt.legend([\"Actual\",\"prediction\"]) \n",
    "plt.title(\"Predicted vs True Value\")\n",
    "plt.xlabel(\"Record number\")\n",
    "plt.ylabel(target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creator: Viraj Jayant, Github: [Profile](https://github.com/Viraj-Jayant)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51a9663a131f1b5758c45b97a2d6917c8ae86b33e231c3733631cbc7265cfc89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
